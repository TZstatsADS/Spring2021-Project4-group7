---
title: "Project 4 Causal Inference"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Propensity Score

Step 0: Set up the environment

```{r}
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("Matching")) install.packages("Matching")
if (!require("glmnet")) install.packages("glmnet")

```

```{r libraries}
library(Matching)
library(glmnet)
library(tidyverse)
```

Step 1: Load Data

```{r}
lowDim <- read.csv("../data/lowDim_dataset.csv")
highDim <- read.csv("../data/highDim_dataset.csv")
```

```{r}
head(lowDim,5)
head(highDim,5)
```

```{r}
# Split into A, x and y
#highDim_dataset
# highA<-highDim$A
# highY<-highDim$Y
# highX<-highDim%>% select(-Y, -A) %>% as.matrix
# 
# #lowDim_dataset
# lowA<-lowDim$A
# lowY<-lowDim$Y
# lowX<-lowDim%>% select(-Y, -A) %>% as.matrix
```

step 2: L2 Penalized Logistic Regression

To avoid overfitting of the logistic regression model, we introduce regularization term to decrease the model variance in the loss function Q


```{r}
propensity_score <- function(data){
  set.seed(0)
  start_time <- Sys.time()
  A<-data$A
  Y<-data$Y
  X<-data%>% select(-Y, -A) %>% as.matrix
  
  
  glm <- cv.glmnet(X, A, family = "binomial", alpha = 0)
  
  p_score <- predict(glm$glmnet.fit, 
                      s = glm$lambda.min, 
                      newx = as.matrix(X),
                      type = "response")
  
  end_time <- Sys.time()
  running_time = end_time - start_time
  #cat("Time for Propensity Matching Low_Dim is:", running_time, "seconds.")
  return(p_score)
}
```


```{r}
# propensity_score(lowDim)
# propensity_score(highDim)
```




# Stratification

Stratification (sometimes referred to as subclassification) is commonly used in observational studies to control for systematic differences between the control and treated groups. This technique consists of grouping subjects into strata determined by observed background characteristics. (D’Agostino, 1998)

We will estimate the Average Treatment Effect (ATE) using stratification based on L2 penalized Logistic Regression propensity scores. The algorithm will be based on the following equation:

$$\hat \Delta_S = \sum_{j=1}^K \frac{N_j}{N} \{N_{1j}^{-1} \sum_{i=1}^N T_i Y_i I(\hat e_i \in \hat Q_j) - N_{0j}^{-1} \sum_{i=1}^N (1-T_i) Y_i I(\hat e_i \in \hat Q_j)\}$$

where K is the number of strata, $N_j$ is the number of individuals in stratum j, $N_{1j}$ is the number of "treated" individuals in stratum j and $N_{0j}$ is the number of "controlled" individuals in stratum j. $\hat Q_j = (\hat q_{j-1}, q_j]$ is the interval from (j-1)th sample quantile to jth sample quantile of the estimated propensity scores. (Lunceford and Davidian, 2004)

## L2 Logistic Regression Propensity Score

```{r}
ps_high = propensity_score(highDim)
ps_low = propensity_score(lowDim)
```

## Estimate Average Treatment Effect (ATE)

We first determine the number of strata K and create equally spaced intervals starting from 0 to 1. In the example below we are using K = 5, and the resulting intervals would be (0, 0.2, 0.4, 0.6, 0.8, 1).

```{r stratification_setup}
K = 5 # number of strata
q = seq(0, 1, by = 1/K) # sample quantile
```


Then we form K strata according to the sample quantiles of the $\hat e_i$ (estimated propensity scores), i = 1, ..., N (sample size/number of observations), where the jth sample quantile $\hat q_j$, for j = 1, ..., K, is such that the proportion of $\hat e_i \leq \hat q_j$ is roughly j/K, $\hat q_0 = 0$ and $\hat q_K = 1$. (Lunceford and Davidian, 2004)

Within each stratum, we subset the observations for the specific strata, i.e. observations whose propensity scores fall in the interval $(q_{j-1},q_j]$. We then split the subsetted data set into "treated" and "controlled" groups using the binary treatment indicator 'A'. For each group within the stratum, we calculate the summation over the multiplication of treatment indicator 'A' and outcome 'Y', and divide the sum by the number of individuals for each group. 

Then the estimated ATE would be the summation over all K strata of the weighted sum of the difference of "treated" and "controlled" groups as described above.


```{r stratification_function}
stratification = function(df, ps){
  tm_start = Sys.time()
  # split into K strata
  stratum = rep(NA, length(q))
  for (i in 1:length(q)){
    stratum[i] = quantile(ps, q[i])
  }
  # ATE
  ate_strata = rep(NA, K)
  for (j in 1:K){
    # select observations whose propensity score is within (q_{j-1},q_j]
    curr.obs = df[which(stratum[j] < ps & ps <= stratum[j+1]),]
    
    # subset/select treatment and control groups
    treatment_strata = curr.obs[curr.obs$A == 1,]
    control_strata = curr.obs[curr.obs$A == 0,]
    
    # calculate sum within stratum
    treatment_sum = sum(treatment_strata$A * treatment_strata$Y) / nrow(treatment_strata)
    control_sum = sum((1 - control_strata$A) * control_strata$Y) / nrow(control_strata)
    ate_strata[j] = (nrow(curr.obs)/nrow(df)) * (treatment_sum - control_sum)
  }
  tm_end = Sys.time()
  cat("The estimated ATE is", sum(ate_strata), "\n")
  cat("Run time is", (tm_end - tm_start), "s")
  return(list(sum(ate_strata), (tm_end - tm_start)))
}
```


### High Dimension Data Set

```{r stratification_high}
strata_high = stratification(highDim, ps_high)
```

### Low Dimension Data Set

```{r stratification_low}
strata_low = stratification(lowDim, ps_low)
```


## Performance

* True ATE for High Dimension Data Set: -54.8558

* True ATE for Low Dimension Data Set: 2.0901


```{r}
true_ate_high = -54.8558
true_ate_low = 2.0901
cat("Performance for High Dimension Data is", abs(true_ate_high - strata_high[[1]]), "\n")
cat("Performance for Low Dimension Data is", abs(true_ate_low - strata_low[[1]]))
```

```{r}
res = matrix(rep(NA,4), ncol = 2)
colnames(res) = c("Performance", "Computational Efficiency")
rownames(res) = c("High Dimension", "Low Dimension")
res[1,1] = abs(true_ate_high - strata_high[[1]])
res[1,2] = abs(true_ate_low - strata_low[[1]])
res[2,1] = strata_high[[2]]
res[2,2] = strata_low[[2]]
res
```


# Regression Estimate with no need of propensity score

## load data

```{r}
lowDim_df <- read.csv('../data/lowDim_dataset.csv')
highDim_df <- read.csv('../data/highDim_dataset.csv')
```

## algorithm

```{r}
Regression_Estimation <- function(df){
  
  start_time <- Sys.time()
  
  # regression model for control groups (A=0)
  model0 <- glm(formula=Y~., data=subset(df[which(df$A==0),],select=-c(A)))
  # regression model for treatment groups (A=1)
  model1 <- glm(formula=Y~., data=subset(df[which(df$A==1),],select=-c(A)))
  
  X = subset(df, select=-c(Y,A)) #input data for prediction
  
  #prediction using model0
  Y0 <- predict(model0, newdata=X)
  #prediction using model1
  Y1 <- predict(model1, newdata=X)
  
  # calculate ATE 
  ATE <- mean(Y1-Y0)
  
  # calculate running time
  end_time <- Sys.time()
  running_time <- end_time - start_time
  
  return (list(ATE=ATE, running_time=running_time))
}
```

## summarize

ATE and running time for low dimension data

```{r}
Regression_Estimation(lowDim_df)
```

ATE and running time for high dimension data

```{r}
Regression_Estimation(highDim_df)
```


# Weighted Regression

```{r load data}
lowDim <- read_csv('../data/lowDim_dataset.csv')
highDim <- read_csv('../data/highDim_dataset.csv') 
```

```{r prep data reg estimate}
df_ld <- lowDim %>% mutate(A = factor(A))
df_hd <- highDim %>% mutate(A = factor(A))
```

```{r}
X_low <- df_ld %>% select(-Y, -A) %>% as.matrix
A_low <- df_ld %>% select(A) %>% as.matrix

X_high <- df_hd %>% select(-Y, -A) %>% as.matrix
A_high <- df_hd %>% select(A) %>% as.matrix

cv_L2_low <- cv.glmnet(X_low, A_low, family = "binomial", alpha = 0)
cv_L2_high <- cv.glmnet(X_high, A_high, family = "binomial", alpha = 0)


```

```{r}
#L2 to get propensity score -low 

L2_low <- glmnet(X_low, A_low, family = "binomial",
                 alpha = 0, lambda = cv_L2$lambda.min)
propensity_score_low <- predict(L2_low, X_low, type = "response")
```

```{r weighted regression - low dim}

# Finding weights - low
t<- as.numeric(A_low)
wt_low <- t/(propensity_score_low) + (1-t)/(1-propensity_score_low)

# Estimate linear regression - low dim:
model_low <- lm(Y~., data = df_ld)
feature_z_low <- summary(model_low)$coef[,4][3:24]<0.05
Y <- df_ld$Y
Z_low <- as.data.frame(cbind(A_low,X_low[,feature_z_low]))
Z_low<-sapply(Z_low, as.numeric)
weighted_low <- lm(Y ~ Z_low, weights = wt_low)
#coef of T is an estimate for ATE
ATE_low <- coef(weighted_low)[2]
ATE_low
```

```{r}
#L2 to get propensity score - high

L2_high <- glmnet(X_high, A_high, family = "binomial",alpha = 0, lambda = cv_L2_high$lambda.min)
propensity_score_high <- predict(L2_high, X_high, type = "response")
```

```{r weighted regression - high dim}

# Finding weights - high
t<- as.numeric(A_high)
wt_high <- t/(propensity_score_high) + (1-t)/(1-propensity_score_high)

# Estimate linear regression - high dim:

model_high <- lm(Y~., data = df_hd)
feature_z_high <- summary(model_high)$coef[,4][3:187]<0.05
Y <- df_hd$Y
Z_high <- as.data.frame(cbind(A_high,X_high[,feature_z_high]))
Z_high<-sapply(Z_high, as.numeric)
weighted_high <- lm(Y ~ Z_high, weights = wt_high)

#coef of T is an estimate for ATE
ATE_high <- coef(weighted_high)[2]
ATE_high


```

```{r}
# Estimate ATE score based on thresholds
thresholds <- c(0.1, 0.05, 0.02, 0.01, 0.005)

ate_scores <- c()
for (t in thresholds) {
  feature_t <- summary(model_high)$coef[,4][3:187]<t
  Z_high_t <- as.data.frame(cbind(A_high, X_high[,feature_t]))
  Z_high_t <- sapply(Z_high_t, as.numeric)
  weighted_high_t <- lm(Y~Z_high_t, weights=wt_high)
  
  ATE_t <- coef(weighted_high_t)[2]
  print(ATE_t)
  append(ate_scores, ATE_t) # can calculate accuracy based on ate_scores
}
```



-----------------------------TO DO: GRAPH/SUMMARIZE ALL RESULTS-----------------------------


# References

D’Agostino, R. B. (1998). Propensity score methods for bias reduction in the comparison of a treatment to a non-randomized control group. Statistics in Medicine, 17(19), 2265-2281. doi:10.1002/(sici)1097-0258(19981015)17:193.0.co;2-b

Lunceford, J. K.; Davidian, M. (2004). Stratification and weighting via the propensity score in estimation of causal treatment effects: A comparative study. Statistics in Medicine, 23(19), 2937-2960. doi:10.1002/sim.1903